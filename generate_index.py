from dotenv import load_dotenv
import os
import pickle
import numpy as np
import faiss
from utils.subtitle_parser import parse_srt
from langchain_community.embeddings import OpenAIEmbeddings
from firebase_utils import sync_subtitles_from_firebase

load_dotenv()
print("FIREBASE_CREDENTIALS_PATH =", os.getenv("FIREBASE_CREDENTIALS_PATH"))
print("BUCKET_NAME =", os.getenv("BUCKET_NAME"))
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("‚ùó OPENAI_API_KEY –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω ‚Äì –ø—Ä–æ–≤–µ—Ä–∏ .env —Ñ–∞–π–ª–∞!")

SUBTITLES_FOLDER = "subtitles"
INDEX_PATH = "embeddings/subtitle_index.faiss"
MAPPING_PATH = "embeddings/subtitle_mapping.pkl"

embedder = OpenAIEmbeddings(openai_api_key=openai_api_key)

# –ó–∞—Ä–µ–∂–¥–∞–º–µ –≤–µ—á–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—â–∏ –∏–Ω–¥–µ–∫—Å–∏ –∏ mapping, –∞–∫–æ –≥–∏ –∏–º–∞
if os.path.exists(INDEX_PATH) and os.path.exists(MAPPING_PATH):
    index = faiss.read_index(INDEX_PATH)
    with open(MAPPING_PATH, "rb") as f:
        mapping = pickle.load(f)
    print(f"üîÅ –ó–∞—Ä–µ–¥–µ–Ω–∏ {len(mapping)} —Å—Ç–∞—Ä–∏ embedding-–∏.")
else:
    index = None
    mapping = {}
    print("‚ö†Ô∏è –ù–µ —Å–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—â–∏ –∏–Ω–¥–µ–∫—Å–∏ ‚Äì —â–µ —Å—ä–∑–¥–∞–¥–µ–º –Ω–æ–≤–∏.")

vectors = []
new_mapping = {}
start_i = max(mapping.keys(), default=-1) + 1
new_i = start_i

existing_texts = set(item["lines"] for item in mapping.values())

print("üü° –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –Ω–æ–≤–∏ —Å—É–±—Ç–∏—Ç—Ä–∏...")

sync_subtitles_from_firebase()

for filename in os.listdir(SUBTITLES_FOLDER):
    if filename.endswith(".srt"):
        movie_name = filename[:-4]
        file_path = os.path.join(SUBTITLES_FOLDER, filename)
        scenes = parse_srt(file_path)

        # üÜï –ù–∞–º–∏—Ä–∞–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—è timestamp –∑–∞ —Ç–æ–∑–∏ —Ñ–∏–ª–º
        last_scene_timestamp = scenes[-1]["timestamp"] if scenes else None

        for scene in scenes:
            text = scene["text"].strip()
            timestamp = scene["timestamp"]

            if not text or text in existing_texts:
                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–º–µ –¥—É–±–ª–∏—Ä–∞–Ω–∏ –∏–ª–∏ –ø—Ä–∞–∑–Ω–∏ —Å—Ü–µ–Ω–∏

            try:
                vector = embedder.embed_query(text)
                vectors.append(vector)

                entry = {
                    "lines": text,
                    "timestamp": timestamp,
                    "movie": movie_name
                }

                # üÜï –î–æ–±–∞–≤—è–º–µ duration —Å–∞–º–æ –≤–µ–¥–Ω—ä–∂ (–ø—Ä–∏ –ø—ä—Ä–≤–∞—Ç–∞ —Å—Ü–µ–Ω–∞ –Ω–∞ —Ç–æ–∑–∏ —Ñ–∏–ª–º)
                if movie_name not in [m["movie"] for m in new_mapping.values()]:
                    entry["duration"] = last_scene_timestamp  # üÜï

                new_mapping[new_i] = entry
                new_i += 1
                existing_texts.add(text)

            except Exception as e:
                print(f"üî¥ –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å—Ü–µ–Ω–∞: {e}")

print(f"üÜï –ù–æ–≤–∏ embedding-–∏: {len(vectors)}")

if vectors:
    vectors_np = np.array(vectors).astype("float32")
    if index is None:
        index = faiss.IndexFlatL2(vectors_np.shape[1])
    index.add(vectors_np)

    # –ê–∫—Ç—É–∞–ª–∏–∑–∏—Ä–∞–º–µ mapping-–∞
    mapping.update(new_mapping)

    # –ó–∞–ø–∏—Å–≤–∞–º–µ
    faiss.write_index(index, INDEX_PATH)
    with open(MAPPING_PATH, "wb") as f:
        pickle.dump(mapping, f)

    print(f"‚úÖ –î–æ–±–∞–≤–µ–Ω–∏ {len(new_mapping)} –Ω–æ–≤–∏ —Å—Ü–µ–Ω–∏ –∫—ä–º –∏–Ω–¥–µ–∫—Å–∞.")
else:
    print("‚ÑπÔ∏è –ù—è–º–∞ –Ω–æ–≤–∏ —Å—Ü–µ–Ω–∏ –∑–∞ –¥–æ–±–∞–≤—è–Ω–µ ‚Äì –≤—Å–∏—á–∫–æ –µ –∞–∫—Ç—É–∞–ª–Ω–æ.")
